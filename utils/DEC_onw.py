import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
from torch.utils.data import TensorDataset, DataLoader
from tqdm import tqdm
from scipy.stats import gaussian_kde
from scipy.signal import argrelextrema
from sklearn.mixture import GaussianMixture


class ScaleClusterNet(nn.Module):
    def __init__(self, in_dim=5, hidden=16, num_scales=3):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(in_dim, hidden),
            nn.ReLU(inplace=True),
            nn.Linear(hidden, num_scales)
        )

    def forward(self, x):
        return self.net(x)


def generate_boxes(img_size=(320, 320), boxes=None):
    if boxes is None:
        boxes = []
    img_w, img_h = img_size
    all_features = []
    for B in range(len(boxes)):
        n_boxes = len(boxes[B])
        for N in range(n_boxes):
            box = boxes[B][N]
            x1, y1, x2, y2 = box
            w, h = box[2] - box[0], box[3] - box[1]
            cx, cy = (x1 + x2) / 2 / img_w, (y1 + y2) / 2 / img_h
            sqrt_area = np.sqrt(w * h)
            all_features.append([sqrt_area, cx, cy, w / img_w, h / img_h])

    return torch.tensor(all_features, dtype=torch.float32)


def generate_random_boxes(img_size=(320, 320), num_images=1000, min_boxes=1, max_boxes=5, box_range=(2, 320)):
    img_w, img_h = img_size
    boxes = []
    for _ in range(num_images):
        box_list = []
        n_boxes = np.random.randint(min_boxes, max_boxes + 1)
        for _ in range(n_boxes):
            w, h = np.random.uniform(box_range[0], box_range[1], 2)
            x1 = np.random.uniform(0, img_w - w)
            y1 = np.random.uniform(0, img_h - h)
            x2 = x1 + w
            y2 = y1 + h
            box = [x1, y1, x2, y2]
            box_list.append(box)

        boxes.append(box_list)

    all_features = generate_boxes(img_size=img_size, boxes=boxes)
    return torch.tensor(all_features, dtype=torch.float32)


def init_pseudo_labels_gmm(features: torch.Tensor, strides: list[int], img_size=(320, 320)):
    img_area = img_size[0] * img_size[1]
    abs_area = features[:, 0] ** 2
    area_ratio = (abs_area / img_area).unsqueeze(1).numpy()

    gmm = GaussianMixture(n_components=len(strides), random_state=0)
    raw_labels = gmm.fit_predict(area_ratio)

    # é¢ç§¯å°çš„æ ‡ç­¾æ˜ å°„ä¸ºå¤§æ„Ÿå—é‡
    mean_area = [area_ratio[raw_labels == i].mean() for i in range(len(strides))]
    sorted_label_map = np.argsort(mean_area)[::-1]  # å°ç›®æ ‡ â†’ å¤§æ„Ÿå—é‡
    labels = torch.tensor([sorted_label_map[i] for i in raw_labels], dtype=torch.long)

    return labels


def init_pseudo_labels_kde(features: torch.Tensor, strides: list[int], img_size=(320, 320)) -> torch.Tensor:
    """
    ä½¿ç”¨ KDE å¯†åº¦ä¼°è®¡ + æå°å€¼ä½œä¸ºåˆ†æ®µç‚¹çš„æ–¹å¼ï¼Œæ›¿ä»£åŸå§‹ quantile æ–¹æ³•ã€‚
    è‡ªåŠ¨è·å–æ„Ÿå—é‡å½’å±çš„ä¼ªæ ‡ç­¾ï¼Œæ»¡è¶³å°ç›®æ ‡ç»™å¤§æ„Ÿå—é‡çš„åŸåˆ™ã€‚
    """
    img_area = img_size[0] * img_size[1]
    abs_area = features[:, 0] ** 2
    area_ratio = abs_area / img_area
    area_ratio_np = area_ratio.cpu().numpy()

    num_scales = len(strides)

    # KDE å¯†åº¦ä¼°è®¡
    kde = gaussian_kde(area_ratio_np)
    x_vals = np.linspace(area_ratio_np.min(), area_ratio_np.max(), 500)
    y_vals = kde(x_vals)

    # å¯»æ‰¾å±€éƒ¨æå°å€¼ä½œä¸ºåˆ†æ®µè¾¹ç•Œï¼ˆè‡³å¤š num_scales-1 ä¸ªï¼‰
    minima_idx = argrelextrema(y_vals, np.less)[0]
    split_candidates = x_vals[minima_idx]

    # å¦‚æœæå°å€¼å¤ªå°‘ï¼Œä¸è¶³ä»¥åˆ† num_scalesï¼Œå°± fallback ä½¿ç”¨ quantile
    if len(split_candidates) < (num_scales - 1):
        print("âš ï¸ KDE åˆ‡åˆ†ç‚¹ä¸è¶³ï¼Œå›é€€ä¸º quantile åˆ†æ®µ")
        quantile_points = torch.linspace(0, 1, steps=num_scales + 1)[1:-1]
        bins = torch.quantile(area_ratio, quantile_points).cpu().numpy()
    else:
        # é€‰å‡ºå‡åŒ€é—´éš”çš„ (num_scales - 1) ä¸ªåˆ†æ®µç‚¹
        bins = np.linspace(0, len(split_candidates) - 1, num_scales - 1).astype(int)
        bins = split_candidates[bins]

    # æ ¹æ® bin åˆ†æ®µ â†’ æ ‡ç­¾ï¼ˆè¶Šå¤§è¶Šå¤§ç›®æ ‡ï¼‰
    labels = np.zeros_like(area_ratio_np, dtype=np.int64)
    for i, b in enumerate(bins):
        labels[area_ratio_np > b] += 1

    # å°ç›®æ ‡ç»™å¤§æ„Ÿå—é‡ï¼šåè½¬æ ‡ç­¾ï¼ˆlabel 0 æ˜¯æœ€å¤§æ„Ÿå—é‡ï¼Œå¯¹åº”å°ç›®æ ‡ï¼‰
    labels = (num_scales - 1) - labels

    return torch.tensor(labels, dtype=torch.long)


def init_pseudo_labels(features: torch.Tensor, strides: list[int], img_size=(320, 320)):
    """
    åŠ¨æ€åˆ’åˆ†ä¼ªæ ‡ç­¾åŒºåŸŸï¼ˆå°ä¸­å¤§ç›®æ ‡ï¼‰ï¼Œæ ¹æ® box å å›¾åƒé¢ç§¯æ¯”ä¾‹
    å¹¶æŒ‰â€œå°ç›®æ ‡ç»™å¤§å°ºåº¦â€åŸåˆ™è¿›è¡Œåå‘åˆ†é…ã€‚
    """
    img_area = img_size[0] * img_size[1]
    abs_area = features[:, 0] ** 2
    area_ratio = abs_area / img_area

    num_scales = len(strides)
    # è‡ªåŠ¨ç”ŸæˆåŒºé—´ç‚¹ï¼Œä¾‹å¦‚3å°ºåº¦ â†’ [0.33, 0.66]ï¼Œ4å°ºåº¦ â†’ [0.25, 0.5, 0.75]
    quantile_points = torch.linspace(0, 1, steps=num_scales + 1)[1:-1]
    bins = torch.quantile(area_ratio, quantile_points)

    # åˆ†é…æ ‡ç­¾ï¼ˆlabelè¶Šå¤§ï¼Œç›®æ ‡è¶Šå¤§ï¼‰
    labels = torch.zeros_like(area_ratio, dtype=torch.long)
    for i, b in enumerate(bins):
        labels[area_ratio > b] += 1
    # å°ç›®æ ‡ç»™å¤§å°ºåº¦ï¼ˆlabelåå‘æ˜ å°„åˆ°strideï¼‰
    labels = (num_scales - 1) - labels

    return labels


def train_unsupervised_model(features: torch.Tensor,
                             pseudo_labels: torch.Tensor,
                             num_scales: int = 3,
                             hidden: int = 16,
                             lr: float = 1e-2,
                             epochs: int = 30,
                             batch_size: int = 256):
    """
    ä½¿ç”¨å°æ‰¹é‡è®­ç»ƒ ScaleClusterNetï¼Œæ‰§è¡Œæ— ç›‘ç£ä¼ªæ ‡ç­¾å­¦ä¹ 
    """
    device = features.device
    dataset = TensorDataset(features, pseudo_labels)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    net = ScaleClusterNet(in_dim=features.shape[1], hidden=hidden, num_scales=num_scales).to(device)
    optimizer = optim.Adam(net.parameters(), lr=lr)
    loss_fn = nn.CrossEntropyLoss()

    tqdm_bar = tqdm(range(epochs), desc="è®­ç»ƒæ¨¡å‹")
    for epoch in tqdm_bar:
        net.train()
        total_loss = 0.0

        for x_batch, y_batch in dataloader:
            x_batch, y_batch = x_batch.to(device), y_batch.to(device)
            logits = net(x_batch)
            loss = loss_fn(logits, y_batch)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item() * x_batch.size(0)

        avg_loss = total_loss / len(dataset)
        tqdm_bar.set_postfix(loss=avg_loss)

    return net


def get_sqrt_area_range_by_scale(net, features, feats_size, num_scales=3):
    net.eval()
    with torch.no_grad():
        logits = net(features)
        preds = torch.argmax(logits, dim=1)
        sqrt_areas = features[:, 0]

    # æŒ‰ç±»åˆ«ç»Ÿè®¡æ¯ç±»é¢ç§¯å‡å€¼
    class_avg = []
    for s in range(num_scales):
        areas = sqrt_areas[preds == s]
        avg = areas.mean().item() if len(areas) > 0 else float('inf')
        class_avg.append((s, avg))

    # é¢ç§¯å°çš„ç±»åˆ« â†’ åˆ†é…ç»™å¤§æ„Ÿå—é‡ï¼ˆstrideå°çš„ï¼‰
    sorted_classes = sorted(class_avg, key=lambda x: x[1])  # ä»å°åˆ°å¤§
    class_to_feat_idx = {
        class_id: feat_idx for feat_idx, (class_id, _) in enumerate(sorted_classes)
    }

    # é‡æ–°ç»Ÿè®¡å¹¶è¾“å‡º
    final_ranges = [None] * num_scales
    for class_id, feat_idx in class_to_feat_idx.items():
        areas = sqrt_areas[preds == class_id]
        if len(areas) > 0:
            min_a, max_a = areas.min().item(), areas.max().item()
            final_ranges[feat_idx] = (min_a, max_a)
        else:
            final_ranges[feat_idx] = (None, None)

    return final_ranges


def train_DEC_(img_size, strides, feats_size, features, epochs=100):
    # print("ğŸ“Œ åˆå§‹åŒ–ä¼ªæ ‡ç­¾ï¼ˆæŒ‰æ„Ÿå—é‡å½’å±ï¼‰...")
    pseudo_labels = init_pseudo_labels_gmm(features, strides, img_size)
    # print("ğŸ§  è®­ç»ƒæç®€è‡ªç›‘ç£èšç±»ç½‘ç»œ...")
    net = train_unsupervised_model(features, pseudo_labels, num_scales=len(strides), epochs=epochs)
    # print("ğŸ“ˆ æ¯ä¸ªå°ºåº¦å¯¹åº” box sqrt(area) èŒƒå›´ï¼š")
    area_ranges = get_sqrt_area_range_by_scale(net, features, feats_size, num_scales=len(strides))

    return area_ranges


# ========================= MAIN =========================
if __name__ == '__main__':
    strides = [8, 16, 32]
    feats_size = [(40, 40), (20, 20), (10, 10)]
    img_size = (320, 320)

    print("â³ æ­£åœ¨ç”Ÿæˆéšæœºæ¡†å¹¶æ„é€ ç‰¹å¾...")
    features = generate_random_boxes(img_size=img_size, num_images=2000)

    area_ranges = train_DEC_(img_size, strides, feats_size, features, epochs=200)
    for i, (min_val, max_val) in enumerate(area_ranges):
        if min_val is not None:
            print(f"  å°ºåº¦ {i + 1} {feats_size[i]} (stride={strides[i]}): sqrt(area) âˆˆ [{min_val:.2f}, {max_val:.2f}]")
        else:
            print(f"  å°ºåº¦ {i + 1} {feats_size[i]} (stride={strides[i]}): æ— æ•°æ®")
